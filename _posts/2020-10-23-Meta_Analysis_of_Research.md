---
layout: post
title: Meta Analysis of Research
---
**Topic:** Artificial Inteligence and Machine Learning  

**Paper:**  
[Emergent Tool Use From Multi-Agent Autocurricula](https://arxiv.org/pdf/1909.07528.pdf)

**Question:**  
The team of computer scientists from OpenAI and Google Brain that wrote this paper was attempting to determine if when a machine learning algorithm is applied to a relatively simple multi-agent competitive game, complex behaviors can emerge. The researchers also wanted to examine how the agents improved their skills competing with one another, how the agents would change the environment for their opponents. For this study, the computer scientists built a modified team-based game of hide and seek and ran a machine learning algorithm through tens of millions of iterations. They then drew data from the number of rewards each team of agents receives, the movement of different objects in the game, the agent's movement, and how quickly different behaviors emerged from the agents' different learning methods are applied.  

**Trust in Findings:**  
I am inclined to believe this study as the data they present shows relatively clear evidence of learning. Looking at the data it can be seen that initially, neither team receives many rewards. Then for a period, the seeking team receives more rewards then, finally, the number of rewards skew heavily towards the hiders. The paper does claim there are two other stages in this process, one of which I can see clear evidence for (I assume the other was only used by a small number of agents or negated by the opposing team quickly as it involved exploiting the game's physics engine). The study also gives convincing data that their approach of letting complex behavior emerge from simply letting the AI play the game is better than training the AI for more specific tasks in the game and that larger batch sizes are conducive to faster learning.  

**Publish or Perish:**  
Publish or perish is the idea that scientists need to publish interesting findings to get funding. In this study I do not believe publish or perish would have played a significant factor. This study appears to have been run and funded by a research company, OpenAI. The OpenAI is currently for-profit, which could raise concerns, but after looking into OpenAI I believe that at the time of this study (the paper I believe was published later at an AI conference) the company was still non-profit. Even today the majority shareholder in OpenAI is a non-profit established to run OpenAI. Although OpenAI does have to worry about funding to some degree, the company does have the backing of some significant figures including Elon Muck who, although no longer on the board of directors, still appears to be donating to OpenAI. OpenAI does appear to have a product they sell (although it is not completely clear whether they are selling or beta-testing a future free service) but it appears to apply to language processing. The study I looked into does not have a clear application in language processing and OpenAI appears to have no current intention of using the techniques described in the study (the code the researchers used in on Github [here](https://github.com/openai/multi-agent-emergence-environments)). The fact that these researchers are for the most part employees of OpenAI (one of the researchers works for Google who I assume is partnering with OpenAI) would suggest that they most likely have a salary and are not dependant on research papers for funding. Because OpenAI appears to have no clear monetary incentive for publishing this study and because the researchers (for the most part) appear to be salaried employees of OpenAI, I do not believe this paper was heavily affected by publish or perish.
